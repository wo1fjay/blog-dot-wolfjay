<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Primary Meta Tags -->
<title>wolfjay | Unstable Diffusion</title>
<meta name="title" content="wolfjay | Unstable Diffusion">
<meta name="description" content="ğŸ³ï¸â€ğŸŒˆ articles and blogs and shit from non-binary naarm/melbourne based artist wolfjay. ">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="blog">
<meta property="og:url" content="/unstable-diffusion">
<meta property="og:title" content="Unstable Diffusion">
<meta property="og:description" content="">
<meta property="og:image" content="https://blog.wolfjay.com/assets/images/blog-le-wolfjay-social-preview.jpg">
<!-- <meta property="og:image" content=" "> -->

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="/unstable-diffusion">
<meta property="twitter:title" content="Unstable Diffusion">
<meta property="twitter:description" content="ğŸ³ï¸â€ğŸŒˆ articles and blogs and shit from non-binary naarm/melbourne based queer indie artist wolfjay :-)">
<meta property="twitter:image" content="https://blog.wolfjay.com/assets/images/blog-le-wolfjay-social-preview.jpg"><link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="blog.wolfjay.com" /><meta name="google-site-verification" content="Z0j8M_BBYx4jeUrlAKWaoPGdeINU2POvf1thuna5KH0" />

</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FQ1117DNW8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FQ1117DNW8');
</script><body><header class="site-header" role="banner" style="background-color: #3E5D36">

  <div class="wrapper" id="header-content">

    <div class="site-header-nav"><a class="site-title" rel="author" href="/"></a>

      <div class="site-header-nav-links">

        <a class="page-link" href="https://wolfjay.bandcamp.com">Bandcamp</a>
        <a class="page-link" href="/links">links</a>

      </div>

    </div>


    <div class="site-header-page-info">
      <p class="post-meta">
        <time class="dt-published" datetime="2022-12-09T21:56:18+11:00" itemprop="datePublished">Dec 9, 2022
        </time>
      </p>
      <h1 class="post-title" itemprop="name headline">Unstable Diffusion</h1>
      <h4 class="post-subtitle">Some q&#39;s about responsibility in the age of AI art</h4>
    </div>

  </div>

  <div class="site-header-emoji-background"><span class="">ğŸ‘¾ ğŸš¨ ğŸŒ</span></div>

</header>

<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <div class="post-content e-content" itemprop="articleBody">
    <p>My timelines were filled this week with artificial intelligence generated illustrations from comedians, musicians, friends, and family - <strong>all very convincingly capturing their likenesses</strong>.</p>

<p>I tried out a few text prompt based AI art generators a few months ago when they first started making waves online. It was possible to make some visually interesting images if you found a sweet spot in the text prompt system, but for the most part their images generated were careless, smeary messes.</p>

<p>What I was seeing now was <strong>different</strong>. Using an image based prompt system where the user uploads photos of themselves, the images Iâ€™ve seen from this new system are, despite being heavily stylised, distinctly recogniseable. They retain key details that make the user look like themselves. I recognised them instantly. They looked like my friends. <strong>They looked like my family.</strong></p>

<p>Caught off guard by how far these tools had come in only a few months, I decided to take another look.</p>

<h5 id="part-1">Part 1:</h5>
<h2 id="tool-or-thief">Tool, or thief?</h2>

<p>From my basic understanding and unscientific research, artificial intelligence systems work by analysing a data set, identifying patterns, then using that data to create rules to follow. A user gives it a prompt, either a word or a phrase or an image, and it generates something based on the prompt following the rules itâ€™s created.</p>

<p><strong>The more data the system has to work with, the more intricate the rules it can create, and the more detailed the result it generates will be.</strong></p>

<p>Iâ€™ve <a href="https://every.to/superorganizers/linus-lee-is-living-with-ai">read about cases</a> where someone will feed an AI system with samples of their work, and use the system to augment and automate parts of their workflow. It seems like a very powerful and positive development. <strong>But what happens when your work is included in a data set without your consent, and used to generate things against your best interests?</strong></p>

<p>Just yesterday I opened Instagram to see @Carlosbob, an artist I follow, <a href="https://www.instagram.com/p/Cl7MkmABQ9-/">posting about discovering that their work was in the latest release of LAIONâ€™s image-text dataset</a>.</p>

<p><img src="../../../../../assets/images/ai-art/carlosbob-instagram.jpg" alt="carlosbob-instagram" /></p>

<figcaption>"Did a quick search and found that almost every painting I've ever shared has been used to train the Al that Lensa is using to create portraits. Lensa app is making a profit on stolen, uncredited and uncompensated art."</figcaption>

<p>So what is AI? Is it a useful tool? Or a faceless thief? Will it make things better? Or way way way fucking worse. Does it even matter? <strong>I tried to find out.</strong></p>

<h5 id="part-2">Part 2:</h5>
<h2 id="unstable-diffusion">Unstable Diffusion.</h2>

<h3 id="--common-crawl">ğŸš¨ â¶ Common Crawl</h3>

<p><a href="https://commoncrawl.org">Common Crawl</a> is where it all starts, a non-profit with the aim of â€œdemocratizing access to web information by producing and maintaining an open repository of web crawl data that is universally accessible and analyzableâ€.</p>

<p>Basically, they look at billions of sites and records that content in a big database, <strong>which is free for anyone to access.</strong></p>

<h3 id="--laion">ğŸš¨ â· LAION</h3>

<p>The next step in the chain is <a href="http://laion.ai">LAION</a> (Large-Scale Artificial Intelligence Open Network), another non-profit that looks up all the content that Common Crawl lists in its database. In particular, it looks at images and their descriptions and adds them to something called a â€˜datasetâ€™.</p>

<p>In September 2022, visual artist Lapine <a href="https://twitter.com/LapineDeLaTerre/status/1570889343845404672">shared on Twitter</a> that they had <strong>found photos of themself taken privately for clinical documentation by a Doctor in 2013 on <a href="https://haveibeentrained.com">â€˜Have I Been Trainedâ€™</a></strong>, a tool created to help artists see if their art had been included in an AI system dataset.</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">ğŸš©My face is in the <a href="https://twitter.com/hashtag/LAION?src=hash&amp;ref_src=twsrc%5Etfw">#LAION</a> dataset. In 2013 a doctor photographed my face as part of clinical documentation. He died in 2018 and somehow that image ended up somewhere online and then ended up in the dataset- the image that I signed a consent form for my doctor- not for a dataset. <a href="https://t.co/TrvjdZtyjD">pic.twitter.com/TrvjdZtyjD</a></p>&mdash; Lapine (@LapineDeLaTerre) <a href="https://twitter.com/LapineDeLaTerre/status/1570889343845404672?ref_src=twsrc%5Etfw">September 16, 2022</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>After the Doctors death in 2018, these images were stolen and published online, making them accessible by Common Crawl, which in turn meant they ended up in LAIONâ€™s dataset.</p>

<p>That dataset currently contains <strong>5 billion entries</strong> of images and text descriptions. Itâ€™s LAIONâ€™s belief that if it is publicly accessible, it is appropriate to catalogue, <strong>regardless of the content, itâ€™s copyright status, or any privacy concerns.</strong></p>

<p><strong>They have no moderation process</strong> for what is entered into their dataset, and while they do accept requests to remove content, they only action requests if the content in question explicitly includes personally identifiable information like someones name, phone number, or address.</p>

<p>It is trivially easy to take content from LAIONâ€™s dataset, <strong>which they make available for free for anyone</strong>, and cross reference it with other online services to quickly find someones personally identifiable information off just a photograph.</p>

<p>Feeling anxious yet?</p>

<h3 id="--stabilityai">ğŸš¨ â¸ Stability.ai</h3>

<p>Stability.ai is the company resonsible for Stable Diffusion, currently one of the main image generating AI systems. Theyâ€™re currently valued at over $1 billion, and <strong>distribute Stable Diffusion for free.</strong></p>

<p><strong>They use LAIONâ€™s dataset to generate images, with no restrictions on what content can be created using their tools.</strong> This includes applying their tool to image of people without their knowledge or consent to create pornographic or violent imagery.</p>

<p>Their founder, Emad Mostaque, told The Verge in September 22 that â€œultimately, itâ€™s peoplesâ€™ responsibility as to whether they are ethical, moral, and legal in how they operate this technologyâ€.</p>

<p><a href="https://stability.ai/blog/stable-diffusion-public-release">They acknowldged</a> when releasing the system to the public that it could be used to create unsafe content, but they hoped â€œeveryone will use this in an ethical, moral and legal mannerâ€.</p>

<p><strong>They recently raised $101 million in their latest funding round to extend the scope of their tool to also include video and audio.</strong></p>

<h3 id="--prisma-labs-and-their-peers">ğŸš¨ â¹ Prisma Labs and their peers</h3>

<p>While heaps companies have been able to build AI image generation tools that use Stable Diffusion due to its open source distribution, Prisma Labsâ€™ Lensa.ai is currently the most popular option.</p>

<p>Though Prisma Labs say they delete all user data after 24 hours, they also say that <strong>they own the images you create. Forever. In perpetuity. With no way to opt out.</strong></p>

<p>In the past, <strong>Prisma labs <a href="https://twitter.com/MildlyAmused/status/1598470417710469120/photo/3">received $2m in investment from Mail.ru</a>,</strong> which was founded by Yuri Milner, who acted as an intermediary for <strong>Vladimir Putin</strong> to make large investments in Facebook and Twitter between 2009 and 2011. They now <a href="https://twitter.com/PrismaAI/status/1598719118399705088?s=20&amp;t=K7tWIcEmLymPMmZqsPhSig">claim on social media</a> that Mail.ru stopped investing in Prisma Labs in 2019, and that the company has no involvement in Russia.</p>

<p><strong>Another tool that offers this functionality, Different Diffusion Me,</strong> looks like a basic web front end for Stable Diffusion, but <strong>is actually run by Tencent,</strong> the Chinese multinational technology and entertainment conglomerate also responsible for TikTok. Tencent last made facial recognition news in 2021 when it used itâ€™s tech to detect when underage users in China were attempting to avoid a state mandated digital curfew of 10pm.</p>

<h5 id="part-3">Part 3:</h5>
<h2 id="bleak-shit">Bleak shit.</h2>

<p>AI generated content is going to affect us all significantly in the very near future. <strong>This is so much more than stylised avatars.</strong> This is about what makes us ourselves.</p>

<p>For decades, weâ€™ve been told to be active on platforms. To share our work, our process, our private lives, ourselves. And in return weâ€™ll be granted visibility. An audience. Attention. Maybe a career, or oppurtunities, or income, or fame.</p>

<p><strong>But what happens when all of that content, all of that imagery, all of those private details find their way into a dataset like LAIONâ€™s?</strong></p>

<p>What happens when someone uses Spotifyâ€™s vast database of music and metadata to extend your listening preferences with AI generated content? Maybe an AI wonâ€™t create the song you open Spotify to listen to, but what about the song that plays automatically after that?</p>

<p>What happens when TikTok or Youtube start serving you supplementary content in the style of your favourite creator? Maybe they donâ€™t try to pretend itâ€™s them, but the avatar on your screen shares their face, or their voice?</p>

<p><img src="../../../../../assets/images/ai-art/la-meme-young-spotify.jpg" alt="la-meme-young-spotify" /></p>

<p>source: <a href="https://www.instagram.com/p/Cl6pZqvO-j3/?igshid=YmMyMTA2M2Y=">La Meme Young on Instagram</a></p>

<p>What happens when you start getting served ads that feature a model who shares physical traits with people youâ€™ve swiped right on on dating apps, or someone wearing an item of clothing youâ€™ve been looking at online, while music plays that sounds <em>almost</em> like your current favourite song?</p>

<p>What happens to your privacy if someone can impersonate you almost perfectly online? Or can post content that youâ€™re not even sure you didnâ€™t post yourself?</p>

<p>What happens to the content we do post, if people become so used to their feeds being full of AI generated content? Will creators have to start emulating trends created by an AI system? What if AI generated content doesnâ€™t replace human created art, but people are happy enough with this new category of simplified and personalised content that they just arenâ€™t bothered with the extra messiness of something made by a human?</p>

<p><strong>What will our art be worth then?</strong></p>

<!-- What happens to consumers of content if they become so hooked on tailor made content designed to ellicit a passive response so they keep consuming? When [criticised that they were censoring protest footage last year](https://www.buzzfeednews.com/article/ryanhatesthis/tiktok-users-are-finally-posting-about-hong-kong-but-only), TikTok said that the content wasn't proliferating across the platform because people just didn't want to see it. They preferred the sickly sweet, overly cheerful, non-critical, snack-sized content that the platform is known for. They had no interest in anything else.

**This is happening now.** -->

<h5 id="part-4">Part 4:</h5>
<h2 id="being-online">Being online.</h2>

<p>We arenâ€™t at that point yet, but itâ€™s not hard to imagine that future, and itâ€™ll be enabled by the way we act online now.</p>

<p><strong>What does it mean to â€œbe onlineâ€ if any action you take, or content you share, just helps an AI to become a better impersonation of you?</strong></p>

<p>If any participation you have in a platform just strengthens a system designed to impede a users ability to act in their own best interest?</p>

<p>In his talk <a href="https://www.youtube.com/watch?v=qIcM21l61TE">â€˜How Designers Ruined The Worldâ€™</a>, Mike Monteiro talks about the effect creating things without also taking responsibility for them can have on the world. â€œWhen designers disregard the effect their work has on our environment they are best negligible, and at worst culpableâ€. When design is practiced without forethought to consequences, without responsibility, what we get is not creation - but destruction.â€</p>

<p>I see very little difference in this context between designers and anyone who is active online.</p>

<p>What responsibility do we have? To each other, and to ourselves?</p>

<h5 id="part-5">Part 5:</h5>
<h2 id="wheres-the-brain">Whereâ€™s the brain?</h2>

<p>I have memories of visiting my Grandma as a child, having recently gotten a new gizmo or gadget. Maybe a Gameboy, or an iPod, or a digital camera. Every single time her reaction to these toys was the same. Caution, verging on disdain.</p>

<p>After several years of being aware of this, she gave a justification. <em>â€œIf you canâ€™t see where itâ€™s brain is, donâ€™t trust it.â€</em></p>

<p>I realised that while, to me, it made sense how these pieces of technology functioned, and what allowed them to perform their functions, it must have been a mystery to my elderly Ukrainian grandmother.</p>

<p>But I now realise that while those memories are still vivid, I have not remembered that lesson while growing up. <strong>I am surrounded by and beholden to things that I absolutely do not understand.</strong> Systems and processes that Iâ€™ve put blind faith in. Either to make money, or participate in a community, or just because itâ€™s what everyone else around me is doing.</p>

<p>My privacy conscious friends have warned me of certain products or fads, but my reaction has often been â€œoh well, if it goes bad I guess weâ€™ll all go down togetherâ€. A fool. What I hadnâ€™t considered are the specific things in my life that are meaningful to me, and how quickly those things could be torn away from me using data Iâ€™ve handed over online without a second thought.</p>

<p>I started this post wanting to better understand the mechanisms that are a part of AI systems, but upon finishing it I realise that <strong>I need to better understand the systems Iâ€™m apart of.</strong></p>

<p>I started writing and researching yesterday morning, around 10:18am. I sat in my lounge room, next to my dog, with some music on. I moved to the kitchen in the afternoon. Today, I finished it off in my study. What have tech companies learned about me during that time? What data points of mine have been added to a dataset that may one day inform an AI system?</p>

<p>Maybe they know from the ambient sensors in my tablet that Iâ€™ve had the lights off, but the curtains open.</p>

<p>Maybe they know from the white noise coming through the microphone in my smartphone that Iâ€™ve had the air conditioner on./</p>

<p>Maybe they know from the photo I sent a friend this morning that Iâ€™m wearing activewear, despite my smartwatch showing Iâ€™ve barely made any progress on my activitiy goals for the day.</p>

<p><strong>How will this information be used?</strong> Will I see more Nike products in my timelines this week? Will I be shown different jobs from recruiters to apply for? Will my utility premiums increase because my provider can see Iâ€™m spending more time at home? Maybe my health insurance premiums will go up because Iâ€™ve been less active than normal.</p>

<p><strong>Of all of these systems, I can definitely start saying no to the obviously superflous ones; the ones asking for my personal data in exchange for some anime avatars.</strong></p>

<p>I can practice being more critical. I can begin to question if the systems around me are actually serving me, or the communities Iâ€™m a part of, or the art I want to create and surround myself with.</p>

<p>And if not?</p>

<h2 id="fuck-off"><strong>Fuck off.</strong></h2>

  </div>

  <!---->

  <a class="u-url" href="/unstable-diffusion" hidden></a><div class="post-blog">
<h3>If you liked this you can <a href="https://ko-fi.com/wo1fjay">tip me a few dollars :)</a></h3>
<p>You can also <a href="https://blog.wolfjay.com/about/">listen to my music on streaming services</a>,<br> or <a href="https://wolfjay.bandcamp.com">buy it on bandcamp,</a> or <a href="/links"> check out more of my work.</a></p>
<p>Thank you for supporting the work of an independent, self-funded, non-binary artist ğŸ˜ŒğŸ§¡âœ¨</p>
</div></article>

      </div>
    </main>

    <!--<footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

    <div class="wrapper">

      
    </div>

</footer>
-->

  </body>

</html>
